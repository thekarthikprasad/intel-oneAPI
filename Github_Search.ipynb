{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "import time\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json"
      ],
      "metadata": {
        "id": "uZ-3_VDcMDba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSKWeDIpLqdG"
      },
      "outputs": [],
      "source": [
        "def fetch_file_tree(repo_owner, repo_name, branch='main'):\n",
        "    url = f'https://api.github.com/repos/{repo_owner}/{repo_name}/git/trees/{branch}?recursive=1'\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "\n",
        "    file_tree = []\n",
        "    for item in data.get('tree', []):\n",
        "        if item['type'] == 'blob':\n",
        "            file_tree.append(item['path'])\n",
        "        elif item['type'] == 'tree':\n",
        "            subtree = fetch_file_tree(repo_owner, repo_name, branch=item['path'])\n",
        "            file_tree.extend([f\"{item['path']}/{subfile}\" for subfile in subtree])\n",
        "    return file_tree\n",
        "\n",
        "def parse_code_from_github(url):\n",
        "    response = requests.get(url)\n",
        "    html_content = response.text\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    script_tag = soup.find(\"script\", {\"type\": \"application/json\", \"data-target\": \"react-app.embeddedData\"})\n",
        "    json_data = script_tag.string\n",
        "    parsed_data = json.loads(json_data)\n",
        "    code_lines = parsed_data['payload']['blob']['rawLines']\n",
        "    return '\\n'.join(code_lines)\n",
        "\n",
        "def parse_ipynb_from_github(url):\n",
        "    query = url.replace(\"https://github.com/\", \"\").replace(\"/blob/\", \"/\").replace(\"github\", \"nbviewer\") + \"?flush_cache=true\"\n",
        "    response = requests.get(f\"https://nbviewer.jupyter.org/{query}\")\n",
        "    return response.text\n",
        "\n",
        "def fetch_and_parse_files(repo_owner, repo_name, file_paths):\n",
        "    for path in file_paths:\n",
        "        if path.endswith('.ipynb'):\n",
        "            code = parse_ipynb_from_github(f\"https://github.com/{repo_owner}/{repo_name}/blob/main/{path}\")\n",
        "        else:\n",
        "            code = parse_code_from_github(f\"https://github.com/{repo_owner}/{repo_name}/blob/main/{path}\")\n",
        "        print(f\"Code from {path}:\")\n",
        "        print(code)\n",
        "        print(\"-----------------------\")\n",
        "\n",
        "def main():\n",
        "    repository_owner = 'krishnaik06'\n",
        "    repository_name = 'Student-Performance-Azure-deployment'\n",
        "    branch_name = 'main'\n",
        "\n",
        "    print(f\"Fetching file tree for '{repository_owner}/{repository_name}' (branch: {branch_name}):\")\n",
        "    file_tree = fetch_file_tree(repository_owner, repository_name, branch=branch_name)\n",
        "    print(file_tree)\n",
        "    print(\"\\nParsing specific files:\")\n",
        "    fetch_and_parse_files(repository_owner, repository_name, file_tree)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\"\n",
        "You are an intelligent search query modeler. you model search queries based on the user prompt.\n",
        "Your task is to model a search query based on the user input.\n",
        "The user inputs a complete description of his problem, you have to find the underlying context, and find key entities\n",
        "Based on the problem, you have to model a search query to search in github.\n",
        "Github uses keyword based search results, so you have to provide search query in such a way that, we end up in appropriate search results.\n",
        "I provide you some tips to model a search query, and also some github search specifics so you can follow that\n",
        "\n",
        "Instructions:\n",
        "\n",
        "-A thing to note when you search by Name and description of the README file is that your search phrase should begin with the in qualifier. This makes it possible to search \"inside\" what you are looking for.\n",
        "\n",
        "Example\n",
        "\n",
        "Using in:name. Let's say you are looking for resources to learn more about Data Science. In this case, you can use the command Data Science in:name which will list repositories with Data Science in the repository name.\n",
        "\n",
        "Using in:description. If you want to find repositories with a ceratin description, for example repositories where the term \"freeCodeCamp\" is included in the descriptionm, our search will be: freecodecamp in:description\n",
        "\n",
        "Using in:readme. You use this to search through a README of a file for a certain phrase. If we want to find repositories where the term freecodecamp is included in the README, our search will be: freecodecamp in:readme.\n",
        "\n",
        "Using in:topic. You use this to find if a certain phrase or word is labeled in the topics. For example to find all repositories where freecodecamp is listed in the topic, our search will be: freecodecamp in:topic\n",
        "\n",
        "You can also combine multiple search queries to further narrow down the search.\n",
        "\n",
        "-How to Find by Stars, Forks\n",
        "You can also search for a repository based on how many stars and forks the project has. This makes it easier for you to know how popular the project is.\n",
        "\n",
        "Examples\n",
        "\n",
        "Using stars:n. If you search for a repository with 1000 stars, then your search query will be stars:1000. This will list repositories with exactly 1000 stars.\n",
        "\n",
        "Using forks:n. This specifies the number of forks a repository should have. If you want find repositories that have less than 100 forks, your search will be: forks:<100.\n",
        "\n",
        "The good thing is that you can always use relational operators like <, >, <=, >= & .. to help you further narrow your search.\n",
        "\n",
        "-How to Find by Language\n",
        "Another cool way to search through GitHub is by language. This helps you filter out repositories to a specific language.\n",
        "\n",
        "Example:\n",
        "\n",
        "-Using language:LANGUAGE. For example if you want to find repositories written in PHP, your search will be: language:PHP\n",
        "How to Find by Organization Name\n",
        "You can also search repositories/projects that are maintained or created by a specific organization. For this you need to begin your search with the keyword org:... followed by the organization name.\n",
        "\n",
        "For example if you search org:freecodecamp it will list repositories that match freeCodeCamp.\n",
        "\n",
        "-How to Find by Date\n",
        "If you want your results based on a specific date, you can search using one of these keywords: created, updated, merged and closed. These keywords should be accompanied by date in the format YYYY-MM-DD.\n",
        "\n",
        "Example:\n",
        "\n",
        "Using keyword:YYYY-MM-DD. Take an instance where we want to make a search of all repositories with the word freeCodeCamp that were created after 2022-10-01. Then our search will be: freecodecamp created:>2022-10-01\n",
        "You can also use <, >, >= and <= to search for dates after, before and on the specified date. To search within a range you can use ....\n",
        "\n",
        "-How to Find by License\n",
        "Licenses are very important when you are are looking for a project to contribute to. Different licenses give different rights as to what a contributor can do or can not do.\n",
        "\n",
        "To make it easier for you to find projects with right licenses you need to have a good understanding of licenses. You can read more about them here.\n",
        "\n",
        "Example:\n",
        "\n",
        "Using license:LICENSE_KEYWORD. This is a good way to search for projects with specific licenses. To search projects with the MIT license, for instance, you would do license:MIT.\n",
        "How to Find by Visibility\n",
        "\n",
        "-You can also conduct your search in terms of the visibility of the repository. In this case you can either use public or private. This will match issues and PRs that are either in a public or private repository, respectively.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Using is:public. This will show a list of public repositories. Let's take an isntance where we want to search all public repositories owned by freeCodCamp. Then our search will be: is:public org:freecodecamp.\n",
        "Using is:private. This query is meant to lists all private repositories under the given search query.\n",
        "\n",
        "\n",
        "\n",
        "Here are even more extra tips:\n",
        "\n",
        "*you can utilize common filter, sort, and searching techniques to easily find specific issues and pull requests of a given project.\n",
        "*is:issue is:open label:beginner - This particular query will list all projects with issues that are open and labeled beginner.\n",
        "*is:issue is:open label:easy - This will list all open issues that are labeled easy.\n",
        "*is:issue is:open label:first-timers-only - This lists all open issues that welcome first-timer contributions.\n",
        "*is:issue is:open label:good-first-bug - This lists projects with open issues labeled good-first-bug, to attract contributors to work on them.\n",
        "*is:issue is:open label:\"good first issue\" - This will list all open issues with the label good first issue, meaning it is good for place for beginners to get started.\n",
        "*is:issue is:open label:starter - This lists all open issues from across GitHub that are labeled starter.\n",
        "*is:issue is:open label:up-for-grabs - This lists open issues that are ready to be worked on if you have the necessary skills.\n",
        "*no:project type:issue is:open - This will list all open issues that are not assigned to a specific project.\n",
        "*no:milestone type:issue is:open - Many times, projects are tracked with milestones. But if you want to find issues that are not tracked, this search query will list those projects for you.\n",
        "*no:label type:issue is:open - This lists all open issues that are not labeled.\n",
        "*is:issue is:open no:assignee - This shows all open issues that have not yet been assigned to a person.\n",
        "\n",
        "Its not necessary that you use all the tips, you can use when required.\n",
        "\n",
        "Criteria: You have to model search queries in a way that ends up in more accurate results in github. always consider the user's requirement while generating\n",
        "You can model accurate search query, even more than one if required.. but make sure it ends up with rich results.\n",
        "\n",
        "Constraints: Your search query should exactly narrow down to user's problem..\n",
        "Input: Here is the user query: {user_prompt}\n",
        "\n",
        "Output: Search query must solve the user problem, use a filter/combination of filters whenever necessary.\n",
        "generate accurate search queries solving user's purpose.\n",
        "Dont give generic quries.\n",
        "Dont give results as filters alone, your output should compulsarily have a search term close to user query.\n",
        "give answer as json\n",
        "{chat_history}\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ma4TqRDRMHlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(temperature=0, groq_api_key=\"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\", model_name=\"mixtral-8x7b-32768\")"
      ],
      "metadata": {
        "id": "WB6F9lFYMMdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate.from_template(template=query)"
      ],
      "metadata": {
        "id": "YBbJcgJLMOVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n"
      ],
      "metadata": {
        "id": "3XS07w3_MQUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(\n",
        "            llm=llm,\n",
        "            prompt=prompt,\n",
        "            verbose=True,\n",
        "            memory=memory)"
      ],
      "metadata": {
        "id": "qD2RUh5aMSnS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.predict(user_prompt=user_prompt)"
      ],
      "metadata": {
        "id": "fWaJW0L-MU0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parser = JsonOutputParser()\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template=query1,\n",
        "    input_variables=[\"user_prompt\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "chain = prompt | llm | parser\n",
        "\n",
        "chain.invoke({\"user_prompt\":user_prompt, \"chat_history\":memory })\n"
      ],
      "metadata": {
        "id": "PKLbghgpMW1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "Now based on the user prompt, we narrowed down search results from the github api... your task is to analyse the file tree, and tell which files of the repo are required to be analysed\n",
        "Important points:\n",
        "- while picking files to be analysed, check with user prompt understanding and analyse...\n",
        "- Pick required files\n",
        "- you can pick documentation files, readme and other things - to make a contextual understanding of the repo..\n",
        "- give file along with folder paths\n",
        "- result set must contain only required files to be analysed, not anything else\n",
        "- Model result as json\n",
        "here is the file tree: {file_tree}\n",
        "you:\n",
        "{chat_history}\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "cHrhq3xtNIZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate.from_template(template=query)"
      ],
      "metadata": {
        "id": "bQlrWwJYNKuH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(\n",
        "            llm=llm,\n",
        "            prompt=prompt,\n",
        "            verbose=True,\n",
        "            memory=memory)"
      ],
      "metadata": {
        "id": "uJMBPUJ_NLMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_tree = get_file_tree('https://api.github.com/repos/Adam-Abera/Personal_Learning_Assistant/git/trees/main?recursive=1')"
      ],
      "metadata": {
        "id": "JoUlMeAMNUCQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.predict(file_tree=repo_tree)"
      ],
      "metadata": {
        "id": "k0LNuRhCNOac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import OllamaEmbeddings"
      ],
      "metadata": {
        "id": "n5mMFD-TMb4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = SimpleDirectoryReader(\"/content/Data\").load_data()"
      ],
      "metadata": {
        "id": "FGmWoj6NMzmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"\n",
        "You are a code analyzer. you have to analyse the code semantically and understand the meaning of it.\n",
        "user will provide his context, based on that you recommend the appropriate code repository\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "hBWofrYOM0C4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_wrapper_prompt = SimpleInputPrompt(\"<|USER|>{query_str}<|ASSISTANT|>\")"
      ],
      "metadata": {
        "id": "2cfsGnQ1M4q9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)"
      ],
      "metadata": {
        "id": "E4avYbioMm0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OllamaEmbeddings(model=\"mistral\")"
      ],
      "metadata": {
        "id": "PT6L_czIMoo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "  return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "Pg9kibo-MrQV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}